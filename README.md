

---

# ğŸŒ¸ SamanthaAI

*A fullstack AI-powered chat assistant with emotional intelligence and reflection capabilities.*

---

## âœ¨ Features

* ğŸ§  Emotion-aware, compassionate responses
* ğŸ” Reflection questions every few turns
* ğŸ§¾ Memory and context support
* âš›ï¸ **Frontend:** React + Vite
* ğŸ **Backend:** Flask with Gemini API integration

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ memory_manager.py
â”‚   â””â”€â”€ prompts/
â”‚       â”œâ”€â”€ compassionate_persona.txt
â”‚       â””â”€â”€ reflection_prompt.txt
â”œâ”€â”€ components/
â”œâ”€â”€ hooks/
â”œâ”€â”€ services/
â”œâ”€â”€ App.tsx
â”œâ”€â”€ index.tsx
â”œâ”€â”€ index.html
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ package.json
â”œâ”€â”€ vite.config.ts
â”œâ”€â”€ .env (backend)
â”œâ”€â”€ .env.local (frontend, optional)
```

---

## âš™ï¸ Setup Instructions

### 1. Backend (Flask)

```bash
# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

* Add your **Gemini API key** to a `.env` file in the `backend/` directory:

  ```
  GOOGLE_API_KEY=your-gemini-api-key-here
  ```

* Start the backend server:

  ```bash
  python app.py
  ```

---

### 2. Frontend (React + Vite)

```bash
# Navigate to the frontend directory
cd frontend

# Install dependencies
npm install

# Start the development server
npm run dev
```

> The frontend is configured to **proxy API requests** to the Flask backend.

---

## ğŸ” Environment Variables

### Backend (`.env`)

```
GOOGLE_API_KEY=your-gemini-api-key
```

### Frontend (`.env.local`) *(Optional)*

```
VITE_GEMINI_API_KEY=your-gemini-api-key
```

> Not required if using backend proxy setup.

---

## ğŸ“„ Prompts

Place the following prompt files in the `backend/prompts/` directory:

* `compassionate_persona.txt`
* `reflection_prompt.txt`

---

## ğŸ› ï¸ Troubleshooting

* If you encounter **500 errors**, check:

  * That your API key is valid
  * That all prompt files are present in the correct directory
* Ensure the backend (e.g. port `5000`) and frontend (e.g. port `5173`) are running and not blocked
* Use the provided `.gitignore` to avoid committing sensitive files like `.env`

---

## ğŸš€ Deployment

* **Backend:** Use a WSGI server like [Gunicorn](https://gunicorn.org/)

* **Frontend:** Build for production:

  ```bash
  npm run build
  ```

* Serve the build folder with your preferred static file server (e.g., Nginx)

---

## ğŸ§  More Info

Refer to the source code and inline comments for deeper understanding of how SamanthaAI works.

---
